# ğŸ—’ï¸ Real-Time Garbage Classifier

A full-stack application that uses a trained machine learning model to classify garbage in real-time using a webcam feed. The app displays predictions in dashboard with bar indicators for each category.
The end-goal is put the "Garbage Classifier" on Raspberry Pi, and place it in the company kitchen

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

* Docker & Docker Compose installed
* A webcam for live video inference

---

### ğŸ’  Development Setup

1. **Clone the repo**

```bash
git clone https://github.com/nir-morad-grabcad/garbage-selector/garbage-selector.git
cd garbage-selector/app
```

2. **Start the development environment**

```bash
docker compose up --build
```

* React dev server: [http://localhost:3001](http://localhost:3001)
* FastAPI backend: [http://localhost:8000](http://localhost:8000)

---

## ğŸ¤– Machine Learning

* **Model Architecture**: The model was trained using [EfficientNetB3](https://keras.io/api/applications/efficientnet/#efficientnetb3-function) from TensorFlowâ€™s Keras applications.
* **Dataset**: Training data included labeled images for five classes: `blue`, `brown`, `green`, `orange`, `yellow`. Images were resized to 224x224 pixels and augmented with flips, rotations, and brightness shifts.
* **Preprocessing**: Images were normalized using the standard `preprocess_input()` function provided by Keras for EfficientNet.
* **Training**: The model was trained for N epochs using categorical crossentropy loss, Adam optimizer, and early stopping. Final accuracy reached over X% on validation.
* **Export**: Saved in `.keras` format and loaded in the FastAPI backend using `load_model()`.
* **Inference**: Webcam frames are preprocessed and passed through the model every 2 frames (\~15â€“30 FPS), and predictions are sent via WebSocket to the frontend.

ğŸ§  Training Tracking System

MLflow was used for tracking experiments, model versions, parameters, and metrics.

Each training run was logged under the ML/mlruns/ directory.

Metrics like accuracy, loss, and learning rate were tracked.

Each checkpoint saved includes the model architecture, weights, and training configuration.

Developers can launch MLflowâ€™s tracking UI locally to review progress:

mlflow ui --backend-store-uri ./ML/mlruns

Visit http://localhost:5000 to view and compare experiments.
---

## ğŸ“Š Frontend Features

* React 19 + TypeScript
* bar UI indicators 
* WebSocket-based real-time updates
* Responsive dashboard with predictions and confidence levels
* Includes full testing setup with Testing Library and Jest types

---

## ğŸ“‚ Environment Variables

`.env.dev` for development:

```env
REACT_APP_WS_URL=ws://localhost:8000/ws
```

`.env` for production:

```env
REACT_APP_WS_URL=ws://backend:8000/ws
```

---

## ğŸ“œ NPM Scripts

| Script          | Purpose                           |
| --------------- | --------------------------------- |
| `npm start`     | Start development server          |
| `npm run build` | Build production bundle           |
| `npm test`      | Run test suite                    |
| `npm run eject` | Eject CRA config (non-reversible) |

---

## ğŸ“› Stopping Containers

```bash
docker compose down --volumes
```

---

## âœï¸ Authors

* [Nir Morad](https://github.com/nir-morad-grabcad/)

---

## ğŸ“„ License

This project is licensed under the MIT License.
